{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "configuration_stablelm_epoch.py: 100%|██████████| 5.27k/5.27k [00:00<00:00, 2.64MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/stabilityai/japanese-stablelm-3b-4e1t-instruct:\n",
      "- configuration_stablelm_epoch.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "modeling_stablelm_epoch.py: 100%|██████████| 27.8k/27.8k [00:00<00:00, 13.9MB/s]\n",
      "A new version of the following files was downloaded from https://huggingface.co/stabilityai/japanese-stablelm-3b-4e1t-instruct:\n",
      "- modeling_stablelm_epoch.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "model.safetensors: 100%|██████████| 5.59G/5.59G [09:05<00:00, 10.2MB/s]\n",
      "generation_config.json: 100%|██████████| 111/111 [00:00<00:00, 53.5kB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "model_name = \"stabilityai/japanese-stablelm-3b-4e1t-instruct\" # stabilityai/japanese-stablelm-instruct-gamma-7b\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "if model_name == \"stabilityai/japanese-stablelm-3b-4e1t-instruct\":\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "else:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.half\n",
    "    )\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "\n",
    "def build_prompt(user_query, inputs=\"\", sep=\"\\n\\n### \"):\n",
    "    # sys_msg = \"あなたは国語教師です。以下の問題を考え、正しい選択肢を説明してください。\"\n",
    "    sys_msg = \"以下は、タスクを説明する指示と、文脈のある入力の組み合わせです。要求を適切に満たす応答を書きなさい。\"\n",
    "    p = sys_msg\n",
    "    roles = [\"指示\", \"応答\"]\n",
    "    msgs = [\": \\n\" + user_query, \": \\n\"]\n",
    "    if inputs:\n",
    "        roles.insert(1, \"入力\")\n",
    "        msgs.insert(1, \": \\n\" + inputs)\n",
    "    for role, msg in zip(roles, msgs):\n",
    "        p += sep + role + msg\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Options</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>___とたん、眠くなった。</td>\n",
       "      <td>a.勉強が終わった b.勉強をした c.勉強をしていた</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>弟は、やっと見つけた就職先なのに、___のうちに、もう辞めてしまった。</td>\n",
       "      <td>a.仕事を覚えたか覚えないか b.働いているかいないか c.友達がいるかいないか</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>この料理、熱いうちに___。</td>\n",
       "      <td>a.おいしいですよ b.召し上がってください c.いい香りいがします</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>交通費は___一方だ。</td>\n",
       "      <td>a.値上がりする b.値上がりしている c.値上がりした</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>___としています。</td>\n",
       "      <td>a.間も無く夏が終わろう b.今日は雨が降ろう c.今年の冬は寒くなろう</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>まだたっぷり時間があったのだから、あんなに___。</td>\n",
       "      <td>a.急ぐことはなかった b.急ぐものではなかった c.急ぐはずがなかった d.急ぐよりほかなかった</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>彼のちょっとした態度だけで自分が嫌われていると思うなんて、___。</td>\n",
       "      <td>a.考えすぎるものだ b.考えすぎというものだ c.考えすぎたものだ d.考えすぎというもの...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>残念ですが、これだけ結果が悪ければ、この計画は失敗だと___。</td>\n",
       "      <td>a.言うものだ b.言ったところだ c.言わないことはない d.言わざるを得ない</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>留学生には日本語だけでなく、日本の文化や社会のことも___。</td>\n",
       "      <td>a.学ぶものだ b.学ばせるものだ c.学びたいものだ d.学んでほしいものだ</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>最近の科学技術の進歩には___</td>\n",
       "      <td>a.驚くべきことがある b.驚くというものだ c.驚くべきものがある d.驚くというものではない</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Question  \\\n",
       "0                          ___とたん、眠くなった。   \n",
       "1    弟は、やっと見つけた就職先なのに、___のうちに、もう辞めてしまった。   \n",
       "2                         この料理、熱いうちに___。   \n",
       "3                            交通費は___一方だ。   \n",
       "4                             ___としています。   \n",
       "..                                   ...   \n",
       "124            まだたっぷり時間があったのだから、あんなに___。   \n",
       "125    彼のちょっとした態度だけで自分が嫌われていると思うなんて、___。   \n",
       "126      残念ですが、これだけ結果が悪ければ、この計画は失敗だと___。   \n",
       "127       留学生には日本語だけでなく、日本の文化や社会のことも___。   \n",
       "128                      最近の科学技術の進歩には___   \n",
       "\n",
       "                                               Options  Answer  \n",
       "0                          a.勉強が終わった b.勉強をした c.勉強をしていた       a  \n",
       "1             a.仕事を覚えたか覚えないか b.働いているかいないか c.友達がいるかいないか       a  \n",
       "2                   a.おいしいですよ b.召し上がってください c.いい香りいがします       b  \n",
       "3                         a.値上がりする b.値上がりしている c.値上がりした       a  \n",
       "4                 a.間も無く夏が終わろう b.今日は雨が降ろう c.今年の冬は寒くなろう       a  \n",
       "..                                                 ...     ...  \n",
       "124  a.急ぐことはなかった b.急ぐものではなかった c.急ぐはずがなかった d.急ぐよりほかなかった       a  \n",
       "125  a.考えすぎるものだ b.考えすぎというものだ c.考えすぎたものだ d.考えすぎというもの...       b  \n",
       "126           a.言うものだ b.言ったところだ c.言わないことはない d.言わざるを得ない       c  \n",
       "127            a.学ぶものだ b.学ばせるものだ c.学びたいものだ d.学んでほしいものだ       d  \n",
       "128   a.驚くべきことがある b.驚くというものだ c.驚くべきものがある d.驚くというものではない       c  \n",
       "\n",
       "[129 rows x 3 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N2 = pd.read_csv('./GrammarDataset/N2_grammar_cleaned.csv')\n",
    "N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    if torch.cuda.is_available():\n",
    "        tokens = tokens.to('cuda')\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(**tokens).logits\n",
    "    return embeddings.cpu().mean(dim=1).squeeze(0)\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n",
    "\n",
    "\n",
    "def ask_sensei(question, options, evaluate=True):\n",
    "    question = question.replace(\"___\", \"[MASK]\")\n",
    "    # Infer with prompt without any additional input\n",
    "    user_inputs = {\n",
    "        \"user_query\":'まず、文法を基づいて、最もよい選択肢のアルファベットを一つ選びなさい。次に、文法について、十五字以内で説明しなさい。',\n",
    "        \"inputs\": f\"問題：{question} 選択肢：{options}\"\n",
    "    }\n",
    "\n",
    "    prompt = build_prompt(**user_inputs)\n",
    "\n",
    "    # print(prompt)\n",
    "    input_ids = tokenizer.encode(\n",
    "        prompt, \n",
    "        add_special_tokens=True, \n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    attention_mask = torch.ones_like(input_ids).to('cuda')  # Create attention mask with all 1s for non-padding tokens\n",
    "\n",
    "    tokens = model.generate(\n",
    "        input_ids.to(device=model.device),\n",
    "        attention_mask=attention_mask, \n",
    "        max_new_tokens=64,\n",
    "        # temperature=0.1,\n",
    "        repetition_penalty=1.1,\n",
    "        # top_p=0.95,\n",
    "        do_sample=False,\n",
    "    )\n",
    "    out = tokenizer.decode(tokens[0][input_ids.shape[1]:], skip_special_tokens=True).strip()\n",
    "\n",
    "    if evaluate:\n",
    "        option_embeddings = [generate_embedding(option) for option in options]\n",
    "        response_embedding = generate_embedding(out)\n",
    "        for index, option_emb in enumerate(option_embeddings):\n",
    "            print(f\"Cosine similarity with option {chr(index+97)} is {cosine_similarity(option_emb, response_embedding)}\")\n",
    "\n",
    "    print(out)\n",
    "    print(\"------------\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity with option a is 0.7913497090339661\n",
      "Cosine similarity with option b is 0.8475881218910217\n",
      "Cosine similarity with option c is 0.9011911749839783\n",
      "Cosine similarity with option d is 0.909726083278656\n",
      "Cosine similarity with option e is 0.8833911418914795\n",
      "Cosine similarity with option f is 0.8619307279586792\n",
      "Cosine similarity with option g is 0.8143980503082275\n",
      "Cosine similarity with option h is 0.8087351322174072\n",
      "Cosine similarity with option i is 0.9255694150924683\n",
      "Cosine similarity with option j is 0.8652255535125732\n",
      "Cosine similarity with option k is 0.8731501698493958\n",
      "Cosine similarity with option l is 0.8475881218910217\n",
      "Cosine similarity with option m is 0.9011911749839783\n",
      "Cosine similarity with option n is 0.909726083278656\n",
      "Cosine similarity with option o is 0.8527827858924866\n",
      "Cosine similarity with option p is 0.8567222952842712\n",
      "Cosine similarity with option q is 0.9255694150924683\n",
      "Cosine similarity with option r is 0.8652255535125732\n",
      "Cosine similarity with option s is 0.874773383140564\n",
      "Cosine similarity with option t is 0.8475881218910217\n",
      "Cosine similarity with option u is 0.9011911749839783\n",
      "Cosine similarity with option v is 0.909726083278656\n",
      "Cosine similarity with option w is 0.8527827858924866\n",
      "Cosine similarity with option x is 0.8567222952842712\n",
      "Cosine similarity with option y is 0.921581506729126\n",
      "Cosine similarity with option z is 0.8702505230903625\n",
      "Cosine similarity with option { is 0.9255694150924683\n",
      "- a.勉強が終わった\n",
      "------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity with option a is 0.784991443157196\n",
      "Cosine similarity with option b is 0.8525782227516174\n",
      "Cosine similarity with option c is 0.9070346355438232\n",
      "Cosine similarity with option d is 0.8580439686775208\n",
      "Cosine similarity with option e is 0.8610917925834656\n",
      "Cosine similarity with option f is 0.8699900507926941\n",
      "Cosine similarity with option g is 0.8754638433456421\n",
      "Cosine similarity with option h is 0.9264522790908813\n",
      "Cosine similarity with option i is 0.8751600980758667\n",
      "Cosine similarity with option j is 0.8699900507926941\n",
      "Cosine similarity with option k is 0.8754638433456421\n",
      "Cosine similarity with option l is 0.8566635251045227\n",
      "Cosine similarity with option m is 0.8750452995300293\n",
      "Cosine similarity with option n is 0.8751600980758667\n",
      "Cosine similarity with option o is 0.8732742667198181\n",
      "Cosine similarity with option p is 0.8601803183555603\n",
      "Cosine similarity with option q is 0.8525782227516174\n",
      "Cosine similarity with option r is 0.915544867515564\n",
      "Cosine similarity with option s is 0.8750452995300293\n",
      "Cosine similarity with option t is 0.9291759133338928\n",
      "Cosine similarity with option u is 0.8750452995300293\n",
      "Cosine similarity with option v is 0.8867676258087158\n",
      "Cosine similarity with option w is 0.8751600980758667\n",
      "Cosine similarity with option x is 0.8750452995300293\n",
      "Cosine similarity with option y is 0.8566635251045227\n",
      "Cosine similarity with option z is 0.8750452995300293\n",
      "Cosine similarity with option { is 0.8751600980758667\n",
      "Cosine similarity with option | is 0.8732742667198181\n",
      "Cosine similarity with option } is 0.8624407052993774\n",
      "Cosine similarity with option ~ is 0.8525782227516174\n",
      "Cosine similarity with option  is 0.9425045847892761\n",
      "Cosine similarity with option  is 0.9283819794654846\n",
      "Cosine similarity with option  is 0.8881542086601257\n",
      "Cosine similarity with option  is 0.8750452995300293\n",
      "Cosine similarity with option  is 0.8867676258087158\n",
      "Cosine similarity with option  is 0.8751600980758667\n",
      "Cosine similarity with option  is 0.8750452995300293\n",
      "Cosine similarity with option  is 0.8566635251045227\n",
      "Cosine similarity with option  is 0.8750452995300293\n",
      "Cosine similarity with option  is 0.8751600980758667\n",
      "- a.仕事を覚えたか覚えないか\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "sensei_ans = []\n",
    "for index, row in N2.iterrows():\n",
    "    answer = ask_sensei(row.Question, row.Options)\n",
    "    sensei_ans.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2['Answer'] = sensei_ans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blip2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
